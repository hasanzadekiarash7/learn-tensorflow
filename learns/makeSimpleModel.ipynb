{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasanzadekiarash7/learn-tensorflow/blob/main/learns/makeSimpleModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make tf models\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras"
      ],
      "metadata": {
        "id": "ysv9w6p91YZU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for this test we work with minst(a good library that has 0 to 9 gesture)\n",
        "minst = keras.datasets.mnist\n",
        "(xtrain,ytrain), (xtest,ytest) = minst.load_data()\n",
        "xtrain,xtest = xtrain // 255, xtest // 255"
      ],
      "metadata": {
        "id": "SqKoM8Jj1q1I"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a sequential model with models.Sequential\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Flatten(input_shape=(28,28)),\n",
        "  keras.layers.Dense(256,activation='relu'),\n",
        "  keras.layers.Dropout(0.3),\n",
        "  keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "# each dense get pervious dense data(amazing copy paste😅)\n",
        "# flatten do this that convert 2d img 28 in 28 to a 1d 724\n",
        "# activation='relu' makes every negative int to zero\n",
        "# with Dropout function each time randomly we disabled denses( so all denses learn this)\n",
        "# why last dense is 10? because output is between 0 to 9 so🧐\n",
        "# activation='softmax' instead of say exact answer say answers with percentage(mathamatical tings)"
      ],
      "metadata": {
        "id": "h_m4s0Jg7SQf",
        "outputId": "dd4184f0-0dfd-4330-f26a-cc155a81f5b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile our model\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "## adam optimizer is a learning strategy that has stable and felxible\n",
        "## and fast learning with momentoum and rmsProps\n",
        "# loss makes numbers only intger\n",
        "# with metrics accuracy we will se each time accuracy avarage. amazing!!!"
      ],
      "metadata": {
        "id": "SozeQGB58W-p"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make test compile ten times(everytimes read and understand 1875 gesture picture(amazing!!))\n",
        "model.fit(xtrain, ytrain, epochs=15,validation_split=0.2)\n",
        "# 15 times we do this:\n",
        "# each time model gets label and picture of the numbers 0 to 9\n",
        "#train all the time with adams optimizer"
      ],
      "metadata": {
        "id": "-DQ161JY88ZP",
        "outputId": "7f5c5a05-c36e-469b-d142-b3e08395882b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3154 - loss: 2.0148 - val_accuracy: 0.4047 - val_loss: 1.6735\n",
            "Epoch 2/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4120 - loss: 1.6467 - val_accuracy: 0.4092 - val_loss: 1.6365\n",
            "Epoch 3/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.4218 - loss: 1.6105 - val_accuracy: 0.4129 - val_loss: 1.6259\n",
            "Epoch 4/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4319 - loss: 1.5729 - val_accuracy: 0.4112 - val_loss: 1.6231\n",
            "Epoch 5/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4350 - loss: 1.5626 - val_accuracy: 0.4133 - val_loss: 1.6184\n",
            "Epoch 6/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.4396 - loss: 1.5497 - val_accuracy: 0.4207 - val_loss: 1.6100\n",
            "Epoch 7/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.4473 - loss: 1.5282 - val_accuracy: 0.4179 - val_loss: 1.6097\n",
            "Epoch 8/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4476 - loss: 1.5240 - val_accuracy: 0.4223 - val_loss: 1.6095\n",
            "Epoch 9/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.4523 - loss: 1.5087 - val_accuracy: 0.4208 - val_loss: 1.6136\n",
            "Epoch 10/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.4587 - loss: 1.4979 - val_accuracy: 0.4227 - val_loss: 1.6189\n",
            "Epoch 11/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4590 - loss: 1.4901 - val_accuracy: 0.4203 - val_loss: 1.6179\n",
            "Epoch 12/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4641 - loss: 1.4743 - val_accuracy: 0.4228 - val_loss: 1.6190\n",
            "Epoch 13/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.4585 - loss: 1.4834 - val_accuracy: 0.4211 - val_loss: 1.6275\n",
            "Epoch 14/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4646 - loss: 1.4651 - val_accuracy: 0.4245 - val_loss: 1.6255\n",
            "Epoch 15/15\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.4685 - loss: 1.4604 - val_accuracy: 0.4200 - val_loss: 1.6317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c8a86bab0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets test and see the accuracy\n",
        "testloss,testacc = model.evaluate(xtest, ytest, verbose=2)\n",
        "print(\"accyracy avarage is: \" + str(testacc))\n",
        "print(\"data losses avarage is: \" + str(testloss))\n",
        "# here we check that avrage of the price he lost and avrage of the accuracy(successfully understand write number)"
      ],
      "metadata": {
        "id": "_IW5iWDV9Gkj",
        "outputId": "d4ebf32f-e831-4cd0-bca9-7f238c2dbc0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 2ms/step - accuracy: 0.4241 - loss: 1.6407\n",
            "accyracy avarage is: 0.42410001158714294\n",
            "data losses avarage is: 1.6407326459884644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets test our model with model.perdict\n",
        "predictions = model.predict(xtest)\n",
        "print(\"your accuracy for first params equal: \" + str(tf.argmax(predictions[1]).numpy()))\n",
        "print(\"label of first params: \" + str(ytest[1]))\n",
        "#  here first model predict.\n",
        "# then with tf.argmax we will find the most model perdiction\n",
        "# and last we show the predict label"
      ],
      "metadata": {
        "id": "Og00wX6k99Ju",
        "outputId": "6e3e136e-67c7-4b71-e1a6-158df3eb948f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "your accuracy for first params equal: 2\n",
            "label of first params: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1NdGqjkG-m6L"
      },
      "execution_count": 48,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "beginner.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}